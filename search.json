[{"title":"统计学相关的函数、随机函数","path":"/2025/05/24/分布函数、随机函数/","content":"统计学相关的函数、随机函数统计学相关的函数 torch.mean() # 返回平均值 torch.sum() # 返回总和 torch.prod() # 计算所有元素的积 torch.max() ＃ 返回最大值 torch.min() ＃ 返回最小值 torch.argmax() # 返回最大值排序的索引值 torch.argmin() # 返回最小值排序的索引值 包含可参数化的概率分布和采样函数（torch.distributions） distributions 包含可参数化的概率分布和采样函数 得分函数 强化学习中策略梯度方法的基础 pathwise derivative估计器 变分自动编码器中的重新参数化技巧 TensoriJtorch.distributions KL Divergence Transforms Constraint ExponentialFamily, Bernoulli, Categorical, Beta, Binomial,Cauchy, Chi2, Dirichlet, Exponential, FisherSnedecor, Gamma, Geometric, Gumbel, HalfCauchy, HalfNormal.Independent, Laplace, LogNormal,LowRankMultivariateNormal, Multinomial,MultivariateNormal,NegativeBinomial, Normal, OneHotCategorical, Pareto,Poisson, RelaxedBernoulli, RelaxedOneHotCategorical,StudentT, TransformedDistribution, Uniform, Weibull 随机抽样定义随机种子+ torch.manual seed（seed） 定义随机数满足的分布+ torch.normal() 范数+ 在泛函分析中，它定义在赋范线性空间中，并满足一定的条件，即①非负性；②齐次性；③三角不等式。 + 常被用来度量某个向量空间（或矩阵）中的每个向量的长度或大小。 o范数&#x2F;1范数&#x2F;2范数&#x2F;p范数&#x2F;核范数+ torch.dist(input, other,p=2) # 汁算p范数 + torch.norm() # 计算2范数","tags":["pytorch","Tensor","函数，统计学相关的函数","随机函数"],"categories":["pytorch"]},{"title":"Tensor的函数","path":"/2025/05/24/Tensor的三角函数/","content":"Tensor的函数三角函数 torch.abs(input, out&#x3D;None) # 计算输入张量中每个元素的绝对值。 torch.cos(input, out&#x3D;None) # 计算输入张量中每个元素的余弦值，输入为弧度制，输出范围 ​[-1, 1]。 torch.acos(input, out&#x3D;None) # 计算反余弦和反正弦值，输出为弧度制。 torch.cosh(input, out&#x3D;None) # 计算双曲余弦和双曲正弦值。 torch.sin(input, out&#x3D;None) # 计算输入张量中每个元素的正弦值（输入为弧度制），输出范围 [-1, 1]。 torch.asin(input, out&#x3D;None) # 计算输入张量的反正弦值（输出为弧度制），输入必须在 [-1, 1] 范围内。 torch.sinh(input, out&#x3D;None) # 计算输入张量的双曲正弦值，数学定义为 sinh(x) &#x3D; (e^x - e^(-x)) &#x2F; 2 torch.tan(input, out&#x3D;None) # 计算正切值，输入为弧度制。 torch.atan(input, out&#x3D;None) # 计算输入张量中每个元素的反正切值（单参数版本），输出范围为 ​[-π&#x2F;2, π&#x2F;2]​。 torch.atan2(input, inpu2,out&#x3D;None) # 根据两个输入参数 input1（y）和 input2（x）计算反正切值，输出范围为 ​[-π, π]，能识别象限。 torch.tanh(input, out&#x3D;None) # 计算双曲正切，输出范围 (-1, 1)。 其他的数学函数 torch.abs() # 绝对值计算​ torch.erf() # 误差函数​ torch.erfinv() # 逆误差函数​ torch.sigmoid() # S 型激活函数​ torch.neg() # 数值取反​ torch.reciprocal() # 倒数计算​ torch.rsqrt() # 平方根倒数​ torch.sign() # 符号函数​ torch.lerp() # 线性插值 torch.addcdiv() # 标量加权除法加法​ torch.addcmul() # 加权逐元素乘法加法​ torch.cumprod() # 累积乘积​ torch.cumsum() # 累积和​","tags":["pytorch","Tensor","函数，三角函数","其他的数学函数"],"categories":["pytorch"]},{"title":"Tensor的基本运算","path":"/2025/05/24/Tensor的基本运算/","content":"Tensor的基本运算取整&#x2F;取余运算 .floor（向下取整数） 地板函数 .ceil（向上取整数） 天花板函数 .round（四舍五入&gt;&#x3D;0.5向上取整，&lt;0.5向下取整） .trunc（裁剪，只取整数部分）“truncation” .frac（只取小数部分）“fracture” %取余 比较运算 torch.eq（input, other, out&#x3D;None）#按成员进行等式操作，相同返回True torch.equal（tensor1, tensor2） #如果tensor1和tensor2有相同的size和elements, 则为true eq与equal的区别： eq：逐元素比较两个张量（或张量与标量）是否相等。 equal：全局判断两个张量是否完全一致（形状相同且所有元素相等）。 torch.ge(input, other, out&#x3D;None) #input&gt;&#x3D;other “​Greater than or Equal” torch.gt(input, other, out&#x3D;None) # input&gt;other “​Greater than” torch.le(input, other, out&#x3D;None) #input&#x3D;&lt;other “Less than or Equal​” torch.lt(input, other, out&#x3D;None) #input&lt;other “Less Than​” torch.ne(input, other, out&#x3D;None) #input!&#x3D;other “Not Equal​” 取前k小&#x2F;第k小的数值及其索引 torch.sort(input, dim&#x3D;None, descending&#x3D;False, out&#x3D;None) #对目标input进行排序 torch.topk（input, k, dim&#x3D;None, largest&#x3D; True, sorted &#x3D;True,out&#x3D;None）#沿着指定维度返回最大k个数值及其索引值 “​Top K Values​” torch.kthvalue(input, k, dim&#x3D;None, out&#x3D;None) #沿着指定维度返回第k个最小值及其索引值 “​K-th Smallest Value​” 判定是否为finite&#x2F;inf&#x2F;nan torch.isfinite(tensor) &#x2F; torch.isinf(tensor) &#x2F; torch.isnan(tensor) 返回一个标记元素是否为 finite&#x2F;inf&#x2F;nan 的mask张量。","tags":["pytorch","Tensor基本运算"],"categories":["pytorch"]},{"title":"in-place 操作和广播机制","path":"/2025/05/24/in-place 和 广播机制/","content":"in-place 操作定义1、 不允许使用临时变量 2、 x = x + y 3、 add_、sub_、mul_等 广播机制定义张量参数可以自动扩展为相同大小。 满足条件1、 每个张量至少有一个维度 2、 满足右对齐 3、 eg： torch.rand(2,1,1)+torch.rand(3) - A: (2, 1, 1) - B: (3,) → 自动补为 (1, 1, 3) 注： 右对齐： 从张量形状（shape）的最右侧维度开始，逐一向左比对维度大小，确保维度兼容后才能进行运算。\\ 满足右对齐的原则： ​右对齐后，每个维度大小相等或其中一个为1​ ​所有维度都满足上述条件​ ps：为什么维度1可以扩展成4，而3不行？​​ 当某个维度大小为1时，表示该维度仅有一个元素。扩展时只需复制该元素到目标维度大小，逻辑明确且无歧义。 如果维度大小为3的张量要扩展成4，必须回答：​第4个元素应该是什么？​​ 是复制第一个元素？还是插值？或者是随机填充？ 这种操作没有统一规则，会导致计算结果不可预测。","tags":["pytorch","in-place操作","广播机制"],"categories":["pytorch"]},{"path":"/2025/05/20/hello-world/","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":["hexo"],"categories":["生活"]}]